import { createSocket } from 'dgram';
import { closeSync, openSync, readSync } from 'fs';
import { open } from 'fs/promises';
import { resolve } from 'path';
import { RtpPacket } from 'werift';

import {
  AV_NOPTS_VALUE,
  AV_PIX_FMT_NONE,
  AV_ROUND_NEAR_INF,
  AV_ROUND_PASS_MINMAX,
  AV_TIME_BASE,
  AV_TIME_BASE_Q,
  AVFLAG_NONE,
  AVFMT_FLAG_CUSTOM_IO,
  AVFMT_FLAG_NONBLOCK,
  AVFMT_TS_DISCONT,
  AVMEDIA_TYPE_AUDIO,
  AVMEDIA_TYPE_VIDEO,
  AVSEEK_CUR,
  AVSEEK_END,
  AVSEEK_SET,
} from '../constants/constants.js';
import { Dictionary } from '../lib/dictionary.js';
import { FFmpegError } from '../lib/error.js';
import { FormatContext } from '../lib/format-context.js';
import { InputFormat } from '../lib/input-format.js';
import { IOContext } from '../lib/io-context.js';
import { Packet } from '../lib/packet.js';
import { Rational } from '../lib/rational.js';
import { avGetPixFmtName, avGetSampleFmtName, avInvQ, avMulQ, avRescaleQ, avRescaleQRnd } from '../lib/utilities.js';
import { DELTA_THRESHOLD, DTS_ERROR_THRESHOLD, IO_BUFFER_SIZE, MAX_INPUT_QUEUE_SIZE } from './constants.js';
import { IOStream } from './io-stream.js';
import { StreamingUtils } from './utilities/streaming.js';

import type { AVMediaType, AVSeekFlag, AVSeekWhence } from '../constants/index.js';
import type { Stream } from '../lib/stream.js';
import type { DemuxerOptions, IOInputCallbacks, RawData, RTPDemuxer } from './types.js';

/**
 * Per-stream timestamp processing state.
 * Tracks timestamp correction and prediction for each stream.
 */
interface StreamState {
  // PTS wrap-around correction
  wrapCorrectionDone: boolean;

  // DTS prediction and tracking
  sawFirstTs: boolean;
  firstDts: bigint;
  nextDts: bigint;
  dts: bigint;
}

/**
 * High-level demuxer for reading and demuxing media files.
 *
 * Provides simplified access to media streams, packets, and metadata.
 * Handles file opening, format detection, and stream information extraction.
 * Supports files, URLs, buffers, and raw data input with automatic cleanup.
 * Essential component for media processing pipelines and transcoding.
 *
 * @example
 * ```typescript
 * import { Demuxer } from 'node-av/api';
 *
 * // Open media file
 * await using input = await Demuxer.open('video.mp4');
 * console.log(`Format: ${input.formatName}`);
 * console.log(`Duration: ${input.duration}s`);
 *
 * // Process packets
 * for await (const packet of input.packets()) {
 *   console.log(`Packet from stream ${packet.streamIndex}`);
 *   packet.free();
 * }
 * ```
 *
 * @example
 * ```typescript
 * // From buffer
 * const buffer = await fs.readFile('video.mp4');
 * await using input = await Demuxer.open(buffer);
 *
 * // Access streams
 * const videoStream = input.video();
 * const audioStream = input.audio();
 * ```
 *
 * @see {@link Muxer} For writing media files
 * @see {@link Decoder} For decoding packets to frames
 * @see {@link FormatContext} For low-level API
 */
export class Demuxer implements AsyncDisposable, Disposable {
  private formatContext: FormatContext;
  private _streams: Stream[] = [];
  private ioContext?: IOContext;
  private isClosed = false;
  private options: Required<DemuxerOptions>;

  // Timestamp processing state (per-stream)
  private streamStates = new Map<number, StreamState>();

  // Timestamp discontinuity tracking (global)
  private tsOffsetDiscont = 0n;
  private lastTs = AV_NOPTS_VALUE;

  // Demux manager for handling multiple parallel packet generators
  private activeGenerators = 0;
  private demuxThread: Promise<void> | null = null;
  private packetQueues = new Map<number | 'all', Packet[]>(); // streamIndex or 'all' -> queue
  private queueResolvers = new Map<number | 'all', () => void>(); // Promise resolvers for waiting consumers
  private demuxThreadActive = false;
  private demuxEof = false;

  /**
   * @param formatContext - Opened format context
   *
   * @param options - Media input options
   *
   * @param ioContext - Optional IO context for custom I/O (e.g., from Buffer)
   *
   * @internal
   */
  private constructor(formatContext: FormatContext, options: Required<DemuxerOptions>, ioContext?: IOContext) {
    this.formatContext = formatContext;
    this.ioContext = ioContext;
    this._streams = formatContext.streams ?? [];
    this.options = options;
  }

  /**
   * Probe media format without fully opening the file.
   *
   * Detects format by analyzing file headers and content.
   * Useful for format validation before processing.
   *
   * Direct mapping to av_probe_input_format().
   *
   * @param input - File path or buffer to probe
   *
   * @returns Format information or null if unrecognized
   *
   * @example
   * ```typescript
   * const info = await Demuxer.probeFormat('video.mp4');
   * if (info) {
   *   console.log(`Format: ${info.format}`);
   *   console.log(`Confidence: ${info.confidence}%`);
   * }
   * ```
   *
   * @example
   * ```typescript
   * // Probe from buffer
   * const buffer = await fs.readFile('video.webm');
   * const info = await Demuxer.probeFormat(buffer);
   * console.log(`MIME type: ${info?.mimeType}`);
   * ```
   *
   * @see {@link InputFormat.probe} For low-level probing
   */
  static async probeFormat(input: string | Buffer): Promise<{
    format: string;
    longName?: string;
    extensions?: string;
    mimeType?: string;
    confidence: number;
  } | null> {
    try {
      if (Buffer.isBuffer(input)) {
        // Probe from buffer
        const format = InputFormat.probe(input);
        if (!format) {
          return null;
        }

        return {
          format: format.name ?? 'unknown',
          longName: format.longName ?? undefined,
          extensions: format.extensions ?? undefined,
          mimeType: format.mimeType ?? undefined,
          confidence: 100, // Direct probe always has high confidence
        };
      } else {
        // For files, read first part and probe
        let fileHandle;
        try {
          fileHandle = await open(input, 'r');
          // Read first 64KB for probing
          const buffer = Buffer.alloc(65536);
          const { bytesRead } = await fileHandle.read(buffer, 0, 65536, 0);

          const probeBuffer = buffer.subarray(0, bytesRead);
          const format = InputFormat.probe(probeBuffer, input);

          if (!format) {
            return null;
          }

          return {
            format: format.name ?? 'unknown',
            longName: format.longName ?? undefined,
            extensions: format.extensions ?? undefined,
            mimeType: format.mimeType ?? undefined,
            confidence: 90, // File-based probe with filename hint
          };
        } catch {
          // If file reading fails, return null
          return null;
        } finally {
          await fileHandle?.close();
        }
      }
    } catch {
      return null;
    }
  }

  /**
   * Probe media format without fully opening the file synchronously.
   * Synchronous version of probeFormat.
   *
   * Detects format by analyzing file headers and content.
   * Useful for format validation before processing.
   *
   * Direct mapping to av_probe_input_format().
   *
   * @param input - File path or buffer to probe
   *
   * @returns Format information or null if unrecognized
   *
   * @example
   * ```typescript
   * const info = Demuxer.probeFormatSync('video.mp4');
   * if (info) {
   *   console.log(`Format: ${info.format}`);
   *   console.log(`Confidence: ${info.confidence}%`);
   * }
   * ```
   *
   * @example
   * ```typescript
   * // Probe from buffer
   * const buffer = fs.readFileSync('video.webm');
   * const info = Demuxer.probeFormatSync(buffer);
   * console.log(`MIME type: ${info?.mimeType}`);
   * ```
   *
   * @see {@link probeFormat} For async version
   */
  static probeFormatSync(input: string | Buffer): {
    format: string;
    longName?: string;
    extensions?: string;
    mimeType?: string;
    confidence: number;
  } | null {
    try {
      if (Buffer.isBuffer(input)) {
        // Probe from buffer
        const format = InputFormat.probe(input);
        if (!format) {
          return null;
        }

        return {
          format: format.name ?? 'unknown',
          longName: format.longName ?? undefined,
          extensions: format.extensions ?? undefined,
          mimeType: format.mimeType ?? undefined,
          confidence: 100, // Direct probe always has high confidence
        };
      } else {
        // For files, read first part and probe
        let fd;
        try {
          fd = openSync(input, 'r');
          // Read first 64KB for probing
          const buffer = Buffer.alloc(65536);
          const bytesRead = readSync(fd, buffer, 0, 65536, 0);

          const probeBuffer = buffer.subarray(0, bytesRead);
          const format = InputFormat.probe(probeBuffer, input);

          if (!format) {
            return null;
          }

          return {
            format: format.name ?? 'unknown',
            longName: format.longName ?? undefined,
            extensions: format.extensions ?? undefined,
            mimeType: format.mimeType ?? undefined,
            confidence: 90, // File-based probe with filename hint
          };
        } catch {
          // If file reading fails, return null
          return null;
        } finally {
          if (fd !== undefined) closeSync(fd);
        }
      }
    } catch {
      return null;
    }
  }

  /**
   * Open media from file, URL, buffer, raw data, or custom I/O callbacks.
   *
   * Automatically detects format and extracts stream information.
   * Supports various input sources with flexible configuration.
   * Creates demuxer ready for packet extraction.
   *
   * Direct mapping to avformat_open_input() and avformat_find_stream_info().
   *
   * @param input - File path, URL, buffer, raw data descriptor, or custom I/O callbacks
   *
   * @param options - Input configuration options
   *
   * @returns Opened demuxer instance
   *
   * @throws {Error} If format not found or open fails, or format required for custom I/O
   *
   * @throws {FFmpegError} If FFmpeg operations fail
   *
   * @example
   * ```typescript
   * // Open file
   * await using input = await Demuxer.open('video.mp4');
   * ```
   *
   * @example
   * ```typescript
   * // Open URL
   * await using input = await Demuxer.open('http://example.com/stream.m3u8');
   * ```
   *
   * @example
   * ```typescript
   * // Open with options
   * await using input = await Demuxer.open('rtsp://camera.local', {
   *   format: 'rtsp',
   *   options: {
   *     rtsp_transport: 'tcp',
   *     analyzeduration: '5000000'
   *   }
   * });
   * ```
   *
   * @example
   * ```typescript
   * // Open raw video data
   * await using input = await Demuxer.open({
   *   type: 'video',
   *   input: rawBuffer,
   *   width: 1920,
   *   height: 1080,
   *   pixelFormat: AV_PIX_FMT_YUV420P,
   *   frameRate: { num: 30, den: 1 }
   * });
   * ```
   *
   * @example
   * ```typescript
   * // Custom I/O callbacks
   * const callbacks = {
   *   read: (size: number) => {
   *     // Read data from custom source
   *     return buffer; // or null for EOF, or negative error code
   *   },
   *   seek: (offset: bigint, whence: AVSeekWhence) => {
   *     // Seek in custom source
   *     return offset; // or negative error code
   *   }
   * };
   *
   * await using input = await Demuxer.open(callbacks, {
   *   format: 'mp4',
   *   bufferSize: 8192
   * });
   * ```
   *
   * @see {@link DemuxerOptions} For configuration options
   * @see {@link RawData} For raw data input
   * @see {@link IOInputCallbacks} For custom I/O interface
   */
  static async open(input: string | Buffer, options?: DemuxerOptions): Promise<Demuxer>;
  static async open(input: IOInputCallbacks, options: (DemuxerOptions | undefined) & { format: string }): Promise<Demuxer>;
  static async open(rawData: RawData, options?: DemuxerOptions): Promise<Demuxer>;
  static async open(input: string | Buffer | RawData | IOInputCallbacks, options: DemuxerOptions = {}): Promise<Demuxer> {
    // Check if input is raw data
    if (typeof input === 'object' && 'type' in input && ('width' in input || 'sampleRate' in input)) {
      // Build options for raw data
      const rawOptions: DemuxerOptions & { format: string } = {
        bufferSize: options.bufferSize,
        format: options.format ?? (input.type === 'video' ? 'rawvideo' : 's16le'),
        options: {
          ...options.options,
        },
      };

      if (input.type === 'video') {
        rawOptions.options = {
          ...rawOptions.options,
          video_size: `${input.width}x${input.height}`,
          pixel_format: avGetPixFmtName(input.pixelFormat) ?? 'yuv420p',
          framerate: new Rational(input.frameRate.num, input.frameRate.den).toString(),
        };
      } else {
        rawOptions.options = {
          ...rawOptions.options,
          sample_rate: input.sampleRate,
          channels: input.channels,
          sample_fmt: avGetSampleFmtName(input.sampleFormat) ?? 's16le',
        };
      }

      input = input.input;
      options = rawOptions;
    }

    // Original implementation for non-raw data
    const formatContext = new FormatContext();
    let ioContext: IOContext | undefined;
    let optionsDict: Dictionary | null = null;
    let inputFormat: InputFormat | null = null;

    try {
      // Create options dictionary if options are provided
      if (options.options) {
        optionsDict = Dictionary.fromObject(options.options);
      }

      // Find input format if specified
      if (options.format) {
        inputFormat = InputFormat.findInputFormat(options.format);
        if (!inputFormat) {
          throw new Error(`Input format '${options.format}' not found`);
        }
      }

      if (typeof input === 'string') {
        // File path or URL - resolve relative paths to absolute
        // Check if it's a URL (starts with protocol://) or a file path
        const isUrl = /^[a-zA-Z][a-zA-Z0-9+.-]*:\/\//.test(input);
        const resolvedInput = isUrl ? input : resolve(input);

        const ret = await formatContext.openInput(resolvedInput, inputFormat, optionsDict);
        FFmpegError.throwIfError(ret, 'Failed to open input');
        formatContext.setFlags(AVFMT_FLAG_NONBLOCK);
      } else if (Buffer.isBuffer(input)) {
        // Validate buffer is not empty
        if (input.length === 0) {
          throw new Error('Cannot open media from empty buffer');
        }
        // From buffer - allocate context first for custom I/O
        formatContext.allocContext();
        ioContext = IOStream.create(input, { bufferSize: options.bufferSize });
        formatContext.pb = ioContext;
        const ret = await formatContext.openInput('', inputFormat, optionsDict);
        FFmpegError.throwIfError(ret, 'Failed to open input from buffer');
      } else if (typeof input === 'object' && 'read' in input) {
        // Custom I/O with callbacks - format is required
        if (!options.format) {
          throw new Error('Format must be specified for custom I/O');
        }

        // Allocate context first for custom I/O
        formatContext.allocContext();

        // Setup custom I/O with callbacks
        ioContext = new IOContext();
        ioContext.allocContextWithCallbacks(options.bufferSize ?? IO_BUFFER_SIZE, 0, input.read, null, input.seek);
        formatContext.pb = ioContext;
        formatContext.setFlags(AVFMT_FLAG_CUSTOM_IO);

        const ret = await formatContext.openInput('', inputFormat, optionsDict);
        FFmpegError.throwIfError(ret, 'Failed to open input from custom I/O');
      } else {
        throw new TypeError('Invalid input type. Expected file path, URL, Buffer, or IOInputCallbacks');
      }

      // Find stream information
      if (!options.skipStreamInfo) {
        const ret = await formatContext.findStreamInfo(null);
        FFmpegError.throwIfError(ret, 'Failed to find stream info');

        // Try to parse extradata for video streams with missing dimensions
        for (const stream of formatContext.streams ?? []) {
          if (stream.codecpar.codecType === AVMEDIA_TYPE_VIDEO) {
            const dimensionsMissing = stream.codecpar.width === 0 || stream.codecpar.height === 0;
            const invalidFormat = stream.codecpar.format === AV_PIX_FMT_NONE;
            const invalidRate = stream.codecpar.frameRate.num === 0 || stream.codecpar.frameRate.den === 0;

            const needsParsing = dimensionsMissing || invalidFormat || invalidRate;
            if (needsParsing && stream.codecpar.extradataSize > 0) {
              stream.codecpar.parseExtradata();
            }
          }
        }
      }

      // Determine buffer size
      let bufferSize = options.bufferSize ?? IO_BUFFER_SIZE;
      if (!ioContext && formatContext.iformat && formatContext.pb) {
        // Check if this is a streaming input (like RTSP, HTTP, etc.)
        const isStreaming = formatContext.pb.seekable === 0;
        if (isStreaming) {
          bufferSize *= 2; // double buffer size for streaming inputs
        }
      }

      // Apply defaults to options
      const fullOptions: Required<DemuxerOptions> = {
        bufferSize,
        format: options.format ?? '',
        skipStreamInfo: options.skipStreamInfo ?? false,
        startWithKeyframe: options.startWithKeyframe ?? false,
        dtsDeltaThreshold: options.dtsDeltaThreshold ?? DELTA_THRESHOLD,
        dtsErrorThreshold: options.dtsErrorThreshold ?? DTS_ERROR_THRESHOLD,
        copyTs: options.copyTs ?? false,
        options: options.options ?? {},
      };

      return new Demuxer(formatContext, fullOptions, ioContext);
    } catch (error) {
      // Clean up only on error
      if (ioContext) {
        // Clear the pb reference first
        formatContext.pb = null;
        // Free the IOContext (for both custom I/O and buffer-based I/O)
        ioContext.freeContext();
      }
      // Clean up FormatContext
      await formatContext.closeInput();
      throw error;
    } finally {
      // Clean up options dictionary
      if (optionsDict) {
        optionsDict.free();
      }
    }
  }

  /**
   * Open media from file, URL, Buffer, raw data, or custom I/O callbacks synchronously.
   * Synchronous version of open.
   *
   * Automatically detects format and extracts stream information.
   * Supports various input sources with flexible configuration.
   * Creates demuxer ready for packet extraction.
   *
   * Direct mapping to avformat_open_input() and avformat_find_stream_info().
   *
   * @param input - File path, URL, Buffer, raw data descriptor, or custom I/O callbacks
   *
   * @param options - Input configuration options
   *
   * @returns Opened muxer instance
   *
   * @throws {Error} If format not found or open fails, or format required for custom I/O
   *
   * @throws {FFmpegError} If FFmpeg operations fail
   *
   * @example
   * ```typescript
   * // Open file
   * using input = Demuxer.openSync('video.mp4');
   * ```
   *
   * @example
   * ```typescript
   * // Open from buffer
   * const buffer = await fs.readFile('video.mp4');
   * using input = Demuxer.openSync(buffer);
   * ```
   *
   * @example
   * ```typescript
   * // Open with options
   * using input = Demuxer.openSync('rtsp://camera.local', {
   *   format: 'rtsp',
   *   options: {
   *     rtsp_transport: 'tcp',
   *     analyzeduration: '5000000'
   *   }
   * });
   * ```
   *
   * @example
   * ```typescript
   * // Custom I/O callbacks
   * const callbacks = {
   *   read: (size: number) => {
   *     // Read data from custom source
   *     return buffer; // or null for EOF, or negative error code
   *   },
   *   seek: (offset: bigint, whence: AVSeekWhence) => {
   *     // Seek in custom source
   *     return offset; // or negative error code
   *   }
   * };
   *
   * using input = Demuxer.openSync(callbacks, {
   *   format: 'mp4',
   *   bufferSize: 8192
   * });
   * ```
   *
   * @see {@link open} For async version
   * @see {@link IOInputCallbacks} For custom I/O interface
   */
  static openSync(input: string | Buffer, options?: DemuxerOptions): Demuxer;
  static openSync(input: IOInputCallbacks, options: (DemuxerOptions | undefined) & { format: string }): Demuxer;
  static openSync(rawData: RawData, options?: DemuxerOptions): Demuxer;
  static openSync(input: string | Buffer | RawData | IOInputCallbacks, options: DemuxerOptions = {}): Demuxer {
    // Check if input is raw data
    if (typeof input === 'object' && 'type' in input && ('width' in input || 'sampleRate' in input)) {
      // Build options for raw data
      const rawOptions: DemuxerOptions & { format: string } = {
        bufferSize: options.bufferSize,
        format: options.format ?? (input.type === 'video' ? 'rawvideo' : 's16le'),
        options: {
          ...options.options,
        },
      };

      if (input.type === 'video') {
        rawOptions.options = {
          ...rawOptions.options,
          video_size: `${input.width}x${input.height}`,
          pixel_format: avGetPixFmtName(input.pixelFormat) ?? 'yuv420p',
          framerate: new Rational(input.frameRate.num, input.frameRate.den).toString(),
        };
      } else {
        rawOptions.options = {
          ...rawOptions.options,
          sample_rate: input.sampleRate,
          channels: input.channels,
          sample_fmt: avGetSampleFmtName(input.sampleFormat) ?? 's16le',
        };
      }

      input = input.input;
      options = rawOptions;
    }

    // Original implementation for non-raw data
    const formatContext = new FormatContext();
    let ioContext: IOContext | undefined;
    let optionsDict: Dictionary | null = null;
    let inputFormat: InputFormat | null = null;

    try {
      // Create options dictionary if options are provided
      if (options.options) {
        optionsDict = Dictionary.fromObject(options.options);
      }

      // Find input format if specified
      if (options.format) {
        inputFormat = InputFormat.findInputFormat(options.format);
        if (!inputFormat) {
          throw new Error(`Input format '${options.format}' not found`);
        }
      }

      if (typeof input === 'string') {
        // File path or URL - resolve relative paths to absolute
        // Check if it's a URL (starts with protocol://) or a file path
        const isUrl = /^[a-zA-Z][a-zA-Z0-9+.-]*:\/\//.test(input);
        const resolvedInput = isUrl ? input : resolve(input);

        const ret = formatContext.openInputSync(resolvedInput, inputFormat, optionsDict);
        FFmpegError.throwIfError(ret, 'Failed to open input');
        formatContext.setFlags(AVFMT_FLAG_NONBLOCK);
      } else if (Buffer.isBuffer(input)) {
        // Validate buffer is not empty
        if (input.length === 0) {
          throw new Error('Cannot open media from empty buffer');
        }
        // From buffer - allocate context first for custom I/O
        formatContext.allocContext();
        ioContext = IOStream.create(input, { bufferSize: options.bufferSize });
        formatContext.pb = ioContext;
        const ret = formatContext.openInputSync('', inputFormat, optionsDict);
        FFmpegError.throwIfError(ret, 'Failed to open input from buffer');
      } else if (typeof input === 'object' && 'read' in input) {
        // Custom I/O with callbacks - format is required
        if (!options.format) {
          throw new Error('Format must be specified for custom I/O');
        }

        // Allocate context first for custom I/O
        formatContext.allocContext();

        // Setup custom I/O with callbacks
        ioContext = new IOContext();
        ioContext.allocContextWithCallbacks(options.bufferSize ?? IO_BUFFER_SIZE, 0, input.read, null, input.seek);
        formatContext.pb = ioContext;
        formatContext.setFlags(AVFMT_FLAG_CUSTOM_IO);

        const ret = formatContext.openInputSync('', inputFormat, optionsDict);
        FFmpegError.throwIfError(ret, 'Failed to open input from custom I/O');
      } else {
        throw new TypeError('Invalid input type. Expected file path, URL, Buffer, or IOInputCallbacks');
      }

      // Find stream information
      if (!options.skipStreamInfo) {
        const ret = formatContext.findStreamInfoSync(null);
        FFmpegError.throwIfError(ret, 'Failed to find stream info');
      }

      // Determine buffer size
      let bufferSize = options.bufferSize ?? IO_BUFFER_SIZE;
      if (!ioContext && formatContext.iformat && formatContext.pb) {
        // Check if this is a streaming input (like RTSP, HTTP, etc.)
        const isStreaming = formatContext.pb.seekable === 0;
        if (isStreaming) {
          bufferSize *= 2; // double buffer size for streaming inputs
        }
      }

      // Apply defaults to options
      const fullOptions: Required<DemuxerOptions> = {
        bufferSize,
        format: options.format ?? '',
        skipStreamInfo: options.skipStreamInfo ?? false,
        startWithKeyframe: options.startWithKeyframe ?? false,
        dtsDeltaThreshold: options.dtsDeltaThreshold ?? DELTA_THRESHOLD,
        dtsErrorThreshold: options.dtsErrorThreshold ?? DTS_ERROR_THRESHOLD,
        copyTs: options.copyTs ?? false,
        options: options.options ?? {},
      };

      return new Demuxer(formatContext, fullOptions, ioContext);
    } catch (error) {
      // Clean up only on error
      if (ioContext) {
        // Clear the pb reference first
        formatContext.pb = null;
        // Free the IOContext (for both custom I/O and buffer-based I/O)
        ioContext.freeContext();
      }
      // Clean up FormatContext
      formatContext.closeInputSync();
      throw error;
    } finally {
      // Clean up options dictionary
      if (optionsDict) {
        optionsDict.free();
      }
    }
  }

  /**
   * Open RTP/SRTP input stream via localhost UDP.
   *
   * Creates a Demuxer from SDP string received via UDP socket.
   * Opens UDP socket and configures FFmpeg to receive and parse RTP packets.
   *
   * @param sdpContent - SDP content string describing the RTP stream
   *
   * @throws {Error} If SDP parsing or socket setup fails
   *
   * @throws {FFmpegError} If FFmpeg operations fail
   *
   * @returns Promise with Demuxer, sendPacket function and cleanup
   *
   * @example
   * ```typescript
   * import { Demuxer, StreamingUtils } from 'node-av/api';
   * import { AV_CODEC_ID_OPUS } from 'node-av/constants';
   *
   * // Generate SDP for SRTP encrypted Opus
   * const sdp = StreamingUtils.createRTPInputSDP([{
   *   port: 5004,
   *   codecId: AV_CODEC_ID_OPUS,
   *   payloadType: 111,
   *   clockRate: 16000,
   *   channels: 1,
   *   srtp: { key: srtpKey, salt: srtpSalt }
   * }]);
   *
   * // Open RTP input
   * const { input, sendPacket, close } = await Demuxer.openSDP(sdp);
   *
   * // Route encrypted RTP packets from network
   * socket.on('message', (msg) => sendPacket(msg));
   *
   * // Decode audio
   * const decoder = await Decoder.create(input.audio()!);
   * for await (const packet of input.packets()) {
   *   const frame = await decoder.decode(packet);
   *   // Process frame...
   * }
   *
   * // Cleanup
   * await close();
   * ```
   *
   * @see {@link StreamingUtils.createInputSDP} to generate SDP content.
   */
  static async openSDP(sdpContent: string): Promise<RTPDemuxer> {
    // Extract all ports from SDP (supports multi-stream: video + audio)
    const ports = StreamingUtils.extractPortsFromSDP(sdpContent);
    if (ports.length === 0) {
      throw new Error('Failed to extract any ports from SDP content');
    }

    // Convert SDP to buffer for custom I/O
    const sdpBuffer = Buffer.from(sdpContent);
    let position = 0;

    // Create custom I/O callbacks for SDP content
    const callbacks: IOInputCallbacks = {
      read: (size: number) => {
        if (position >= sdpBuffer.length) {
          return null; // EOF
        }
        const chunk = sdpBuffer.subarray(position, Math.min(position + size, sdpBuffer.length));
        position += chunk.length;
        return chunk;
      },
      seek: (offset: bigint, whence: AVSeekWhence) => {
        const offsetNum = Number(offset);
        if (whence === AVSEEK_SET) {
          position = offsetNum;
        } else if (whence === AVSEEK_CUR) {
          position += offsetNum;
        } else if (whence === AVSEEK_END) {
          position = sdpBuffer.length + offsetNum;
        }
        return position;
      },
    };

    // Create UDP socket for sending packets to FFmpeg
    const udpSocket = createSocket('udp4');

    try {
      // Open Demuxer with SDP format using custom I/O
      const input = await Demuxer.open(callbacks, {
        format: 'sdp',
        skipStreamInfo: true,
        options: {
          protocol_whitelist: 'pipe,udp,rtp,file,crypto',
          listen_timeout: -1,
        },
      });

      const sendPacket = (rtpPacket: Buffer | RtpPacket, streamIndex = 0) => {
        const port = ports[streamIndex];
        if (!port) {
          throw new Error(`No port found for stream index ${streamIndex}. Available streams: ${ports.length}`);
        }
        const data = rtpPacket instanceof RtpPacket ? rtpPacket.serialize() : rtpPacket;
        udpSocket.send(data, port, '127.0.0.1');
      };

      const close = async () => {
        await input.close();
        udpSocket.close();
      };

      const closeSync = () => {
        input.closeSync();
        udpSocket.close();
      };

      return { input, sendPacket, close, closeSync };
    } catch (error) {
      // Cleanup on error
      udpSocket.close();
      throw error;
    }
  }

  /**
   * Open RTP/SRTP input stream via localhost UDP synchronously.
   * Synchronous version of openSDP.
   *
   * Creates a Demuxer from SDP string received via UDP socket.
   * Opens UDP socket and configures FFmpeg to receive and parse RTP packets.
   *
   * @param sdpContent - SDP content string describing the RTP stream
   *
   * @throws {Error} If SDP parsing or socket setup fails
   *
   * @throws {FFmpegError} If FFmpeg operations fail
   *
   * @returns Object with Demuxer, sendPacket function and cleanup
   *
   * @example
   * ```typescript
   * import { Demuxer, StreamingUtils } from 'node-av/api';
   * import { AV_CODEC_ID_OPUS } from 'node-av/constants';
   *
   * // Generate SDP for SRTP encrypted Opus
   * const sdp = StreamingUtils.createRTPInputSDP([{
   *   port: 5004,
   *   codecId: AV_CODEC_ID_OPUS,
   *   payloadType: 111,
   *   clockRate: 16000,
   *   channels: 1,
   *   srtp: { key: srtpKey, salt: srtpSalt }
   * }]);
   *
   * // Open RTP input
   * const { input, sendPacket, closeSync } = Demuxer.openSDPSync(sdp);
   *
   * // Route encrypted RTP packets from network
   * socket.on('message', (msg) => sendPacket(msg));
   *
   * // Decode audio
   * const decoder = await Decoder.create(input.audio()!);
   * for await (const packet of input.packets()) {
   *   const frame = await decoder.decode(packet);
   *   // Process frame...
   * }
   *
   * // Cleanup synchronously
   * closeSync();
   * ```
   *
   * @see {@link StreamingUtils.createInputSDP} to generate SDP content.
   * @see {@link openSDP} For async version
   */
  static openSDPSync(sdpContent: string): RTPDemuxer {
    // Extract all ports from SDP (supports multi-stream: video + audio)
    const ports = StreamingUtils.extractPortsFromSDP(sdpContent);
    if (ports.length === 0) {
      throw new Error('Failed to extract any ports from SDP content');
    }

    // Convert SDP to buffer for custom I/O
    const sdpBuffer = Buffer.from(sdpContent);
    let position = 0;

    // Create custom I/O callbacks for SDP content
    const callbacks: IOInputCallbacks = {
      read: (size: number) => {
        if (position >= sdpBuffer.length) {
          return null; // EOF
        }
        const chunk = sdpBuffer.subarray(position, Math.min(position + size, sdpBuffer.length));
        position += chunk.length;
        return chunk;
      },
      seek: (offset: bigint, whence: AVSeekWhence) => {
        const offsetNum = Number(offset);
        if (whence === AVSEEK_SET) {
          position = offsetNum;
        } else if (whence === AVSEEK_CUR) {
          position += offsetNum;
        } else if (whence === AVSEEK_END) {
          position = sdpBuffer.length + offsetNum;
        }
        return position;
      },
    };

    // Create UDP socket for sending packets to FFmpeg
    const udpSocket = createSocket('udp4');

    try {
      // Open Demuxer with SDP format using custom I/O
      const input = Demuxer.openSync(callbacks, {
        format: 'sdp',
        skipStreamInfo: true,
        options: {
          protocol_whitelist: 'pipe,udp,rtp,file,crypto',
          listen_timeout: -1,
        },
      });

      const sendPacket = (rtpPacket: Buffer | RtpPacket, streamIndex = 0) => {
        const port = ports[streamIndex];
        if (!port) {
          throw new Error(`No port found for stream index ${streamIndex}. Available streams: ${ports.length}`);
        }
        const data = rtpPacket instanceof RtpPacket ? rtpPacket.serialize() : rtpPacket;
        udpSocket.send(data, port, '127.0.0.1');
      };

      const close = async () => {
        await input.close();
        udpSocket.close();
      };

      const closeSync = () => {
        input.closeSync();
        udpSocket.close();
      };

      return { input, sendPacket, close, closeSync };
    } catch (error) {
      // Cleanup on error
      udpSocket.close();
      throw error;
    }
  }

  /**
   * Check if input is open.
   *
   * @example
   * ```typescript
   * if (!input.isInputOpen) {
   *   console.log('Input is not open');
   * }
   * ```
   */
  get isInputOpen(): boolean {
    return !this.isClosed;
  }

  /**
   * Get all streams in the media.
   *
   * @example
   * ```typescript
   * for (const stream of input.streams) {
   *   console.log(`Stream ${stream.index}: ${stream.codecpar.codecType}`);
   * }
   * ```
   */
  get streams(): Stream[] {
    return this._streams;
  }

  /**
   * Get media duration in seconds.
   *
   * Returns 0 if duration is unknown or not available or input is closed.
   *
   * @example
   * ```typescript
   * console.log(`Duration: ${input.duration} seconds`);
   * ```
   */
  get duration(): number {
    if (this.isClosed) {
      return 0;
    }

    const duration = this.formatContext.duration;
    if (!duration || duration <= 0) {
      return 0;
    }

    // Convert from AV_TIME_BASE (microseconds) to seconds
    return Number(duration) / 1000000;
  }

  /**
   * Get media bitrate in kilobits per second.
   *
   * Returns 0 if bitrate is unknown or not available or input is closed.
   *
   * @example
   * ```typescript
   * console.log(`Bitrate: ${input.bitRate} kbps`);
   * ```
   */
  get bitRate(): number {
    if (this.isClosed) {
      return 0;
    }

    const bitrate = this.formatContext.bitRate;
    if (!bitrate || bitrate <= 0) {
      return 0;
    }

    // Convert from bits per second to kilobits per second
    return Number(bitrate) / 1000;
  }

  /**
   * Get media metadata.
   *
   * Returns all metadata tags as key-value pairs.
   *
   * @example
   * ```typescript
   * const metadata = input.metadata;
   * console.log(`Title: ${metadata.title}`);
   * console.log(`Artist: ${metadata.artist}`);
   * ```
   */
  get metadata(): Record<string, string> {
    if (this.isClosed) {
      return {};
    }

    return this.formatContext.metadata?.getAll() ?? {};
  }

  /**
   * Get format name.
   *
   * Returns 'unknown' if input is closed or format is not available.
   *
   * @example
   * ```typescript
   * console.log(`Format: ${input.formatName}`); // "mov,mp4,m4a,3gp,3g2,mj2"
   * ```
   */
  get formatName(): string {
    if (this.isClosed) {
      return 'unknown';
    }

    return this.formatContext.iformat?.name ?? 'unknown';
  }

  /**
   * Get format long name.
   *
   * Returns 'Unknown Format' if input is closed or format is not available.
   *
   * @example
   * ```typescript
   * console.log(`Format: ${input.formatLongName}`); // "QuickTime / MOV"
   * ```
   */
  get formatLongName(): string {
    if (this.isClosed) {
      return 'Unknown Format';
    }

    return this.formatContext.iformat?.longName ?? 'Unknown Format';
  }

  /**
   * Get MIME type of the input format.
   *
   * Returns null if input is closed or format is not available.
   *
   * @example
   * ```typescript
   * console.log(`MIME Type: ${input.mimeType}`); // "video/mp4"
   * ```
   */
  get mimeType(): string | null {
    if (this.isClosed) {
      return null;
    }

    return this.formatContext.iformat?.mimeType ?? null;
  }

  /**
   * Get input stream by index.
   *
   * Returns the stream at the specified index.
   *
   * @param index - Stream index
   *
   * @returns Stream or undefined if index is invalid
   *
   * @example
   * ```typescript
   * const input = await Demuxer.open('input.mp4');
   *
   * // Get the input stream to inspect codec parameters
   * const stream = input.getStream(1); // Get stream at index 1
   * if (stream) {
   *   console.log(`Input codec: ${stream.codecpar.codecId}`);
   * }
   * ```
   *
   * @see {@link video} For getting video streams
   * @see {@link audio} For getting audio streams
   */
  getStream(index: number): Stream | undefined {
    const streams = this.formatContext.streams;
    if (!streams || index < 0 || index >= streams.length) {
      return undefined;
    }
    return streams[index];
  }

  /**
   * Get video stream by index.
   *
   * Returns the nth video stream (0-based index).
   * Returns undefined if stream doesn't exist.
   *
   * @param index - Video stream index (default: 0)
   *
   * @returns Video stream or undefined
   *
   * @example
   * ```typescript
   * const videoStream = input.video();
   * if (videoStream) {
   *   console.log(`Video: ${videoStream.codecpar.width}x${videoStream.codecpar.height}`);
   * }
   * ```
   *
   * @example
   * ```typescript
   * // Get second video stream
   * const secondVideo = input.video(1);
   * ```
   *
   * @see {@link audio} For audio streams
   * @see {@link findBestStream} For automatic selection
   */
  video(index = 0): Stream | undefined {
    const streams = this._streams.filter((s) => s.codecpar.codecType === AVMEDIA_TYPE_VIDEO);
    return streams[index];
  }

  /**
   * Get audio stream by index.
   *
   * Returns the nth audio stream (0-based index).
   * Returns undefined if stream doesn't exist.
   *
   * @param index - Audio stream index (default: 0)
   *
   * @returns Audio stream or undefined
   *
   * @example
   * ```typescript
   * const audioStream = input.audio();
   * if (audioStream) {
   *   console.log(`Audio: ${audioStream.codecpar.sampleRate}Hz`);
   * }
   * ```
   *
   * @example
   * ```typescript
   * // Get second audio stream
   * const secondAudio = input.audio(1);
   * ```
   *
   * @see {@link video} For video streams
   * @see {@link findBestStream} For automatic selection
   */
  audio(index = 0): Stream | undefined {
    const streams = this._streams.filter((s) => s.codecpar.codecType === AVMEDIA_TYPE_AUDIO);
    return streams[index];
  }

  /**
   * Get input format details.
   *
   * Returns null if input is closed or format is not available.
   *
   * @returns Input format or null
   *
   * @example
   * ```typescript
   * const inputFormat = input.inputFormat;
   * if (inputFormat) {
   *   console.log(`Input Format: ${inputFormat.name}`);
   * }
   * ```
   */
  inputFormat(): InputFormat | null {
    return this.formatContext.iformat;
  }

  /**
   * Find the best stream of a given type.
   *
   * Uses FFmpeg's stream selection algorithm.
   * Considers codec support, default flags, and quality.
   *
   * Direct mapping to av_find_best_stream().
   *
   * @param type - Media type to find
   *
   * @returns Best stream or undefined if not found or input is closed
   *
   * @example
   * ```typescript
   * import { AVMEDIA_TYPE_VIDEO } from 'node-av/constants';
   *
   * const bestVideo = input.findBestStream(AVMEDIA_TYPE_VIDEO);
   * if (bestVideo) {
   *   const decoder = await Decoder.create(bestVideo);
   * }
   * ```
   *
   * @see {@link video} For direct video stream access
   * @see {@link audio} For direct audio stream access
   */
  findBestStream(type: AVMediaType): Stream | undefined {
    if (this.isClosed) {
      return undefined;
    }

    const bestStreamIndex = this.formatContext.findBestStream(type);
    return this._streams.find((s) => s.index === bestStreamIndex);
  }

  /**
   * Read packets from media as async generator.
   *
   * Yields demuxed packets for processing.
   * Automatically handles packet memory management.
   * Optionally filters packets by stream index.
   *
   * **Supports parallel generators**: Multiple `packets()` iterators can run concurrently.
   * When multiple generators are active, an internal demux thread automatically handles
   * packet distribution to avoid race conditions.
   *
   * Direct mapping to av_read_frame().
   *
   * @param index - Optional stream index to filter
   *
   * @yields {Packet} Demuxed packets (must be freed by caller)
   *
   * @throws {Error} If packet cloning fails
   *
   * @example
   * ```typescript
   * // Read all packets
   * for await (const packet of input.packets()) {
   *   console.log(`Packet: stream=${packet.streamIndex}, pts=${packet.pts}`);
   *   packet.free();
   * }
   * ```
   *
   * @example
   * ```typescript
   * // Read only video packets
   * const videoStream = input.video();
   * for await (const packet of input.packets(videoStream.index)) {
   *   // Process video packet
   *   packet.free();
   * }
   * ```
   *
   * @example
   * ```typescript
   * // Parallel processing of video and audio streams
   * const videoGen = input.packets(videoStream.index);
   * const audioGen = input.packets(audioStream.index);
   *
   * await Promise.all([
   *   (async () => {
   *     for await (const packet of videoGen) {
   *       // Process video
   *       packet.free();
   *     }
   *   })(),
   *   (async () => {
   *     for await (const packet of audioGen) {
   *       // Process audio
   *       packet.free();
   *     }
   *   })()
   * ]);
   * ```
   *
   * @see {@link Decoder.frames} For decoding packets
   */
  async *packets(index?: number): AsyncGenerator<Packet | null> {
    // Register this generator
    this.activeGenerators++;
    const queueKey = index ?? 'all';

    // Initialize queue for this generator
    if (!this.packetQueues.has(queueKey)) {
      this.packetQueues.set(queueKey, []);
    }

    // Always start demux thread (handles single and multiple generators)
    this.startDemuxThread();

    try {
      let hasSeenKeyframe = !this.options.startWithKeyframe;

      // Read from queue (demux thread is handling av_read_frame)
      const queue = this.packetQueues.get(queueKey)!;

      while (!this.isClosed) {
        // Try to get packet from queue
        let packet = queue.shift();

        // If queue is empty, wait for next packet
        if (!packet) {
          // Check for EOF first
          if (this.demuxEof) {
            break; // End of stream
          }

          // Create promise and register resolver
          const { promise, resolve } = Promise.withResolvers<void>();
          this.queueResolvers.set(queueKey, resolve);

          // Wait for demux thread to add packet
          await promise;

          // Check again after wakeup
          if (this.demuxEof) {
            break;
          }

          packet = queue.shift();
          if (!packet) {
            continue;
          }
        }

        // Apply keyframe filtering if needed
        if (!hasSeenKeyframe) {
          const stream = this._streams[packet.streamIndex];
          const isVideoStream = stream?.codecpar.codecType === AVMEDIA_TYPE_VIDEO;

          if (isVideoStream && packet.isKeyframe) {
            hasSeenKeyframe = true;
          } else if (isVideoStream && !packet.isKeyframe) {
            packet.free();
            continue;
          }
        }

        yield packet;
      }
    } finally {
      // Unregister this generator
      this.activeGenerators--;

      // Stop demux thread if no more generators
      if (this.activeGenerators === 0) {
        await this.stopDemuxThread();
      }

      yield null; // Signal EOF
    }
  }

  /**
   * Read packets from media as generator synchronously.
   * Synchronous version of packets.
   *
   * Yields demuxed packets for processing.
   * Automatically handles packet memory management.
   * Optionally filters packets by stream index.
   *
   * Direct mapping to av_read_frame().
   *
   * @param index - Optional stream index to filter
   *
   * @yields {Packet} Demuxed packets (must be freed by caller)
   *
   * @throws {Error} If packet cloning fails
   *
   * @example
   * ```typescript
   * // Read all packets
   * for (const packet of input.packetsSync()) {
   *   console.log(`Packet: stream=${packet.streamIndex}, pts=${packet.pts}`);
   *   packet.free();
   * }
   * ```
   *
   * @example
   * ```typescript
   * // Read only video packets
   * const videoStream = input.video();
   * for (const packet of input.packetsSync(videoStream.index)) {
   *   // Process video packet
   *   packet.free();
   * }
   * ```
   *
   * @see {@link packets} For async version
   */
  *packetsSync(index?: number): Generator<Packet | null> {
    using packet = new Packet();
    packet.alloc();
    let hasSeenKeyframe = !this.options.startWithKeyframe;

    while (!this.isClosed) {
      const ret = this.formatContext.readFrameSync(packet);
      if (ret < 0) {
        break;
      }

      // Get stream for timestamp processing
      const stream = this._streams[packet.streamIndex];
      if (stream) {
        // Set packet timebase to stream timebase
        // This must be done BEFORE any timestamp processing
        packet.timeBase = stream.timeBase;

        // Apply timestamp processing
        // 1. PTS wrap-around correction
        this.ptsWrapAroundCorrection(packet, stream);
        // 2. Timestamp discontinuity processing
        this.timestampDiscontinuityProcess(packet, stream);
        // 3. DTS prediction/update
        this.dtsPredict(packet, stream);
      }

      if (index === undefined || packet.streamIndex === index) {
        // If startWithKeyframe is enabled, skip packets until we see a keyframe
        // Only apply to video streams - audio packets should always pass through
        if (!hasSeenKeyframe) {
          const stream = this._streams[packet.streamIndex];
          const isVideoStream = stream?.codecpar.codecType === AVMEDIA_TYPE_VIDEO;

          if (isVideoStream && packet.isKeyframe) {
            hasSeenKeyframe = true;
          } else if (isVideoStream && !packet.isKeyframe) {
            // Skip video P-frames until first keyframe
            packet.unref();
            continue;
          }
          // Non-video streams (audio, etc.) always pass through
        }

        // Clone the packet for the user
        // This creates a new Packet object that shares the same data buffer
        // through reference counting. The data won't be freed until both
        // the original and the clone are unreferenced.
        const cloned = packet.clone();
        if (!cloned) {
          throw new Error('Failed to clone packet (out of memory)');
        }
        yield cloned;
      }

      // Unreference the original packet's data buffer
      // This allows us to reuse the packet object for the next readFrame()
      // The data itself is still alive because the clone has a reference
      packet.unref();
    }

    // Signal EOF
    yield null;
  }

  /**
   * Seek to timestamp in media.
   *
   * Seeks to the specified position in seconds.
   * Can seek in specific stream or globally.
   *
   * Direct mapping to av_seek_frame().
   *
   * @param timestamp - Target position in seconds
   *
   * @param streamIndex - Stream index or -1 for global (default: -1)
   *
   * @param flags - Seek flags (default: AVFLAG_NONE)
   *
   * @returns 0 on success, negative on error
   *
   * @throws {Error} If input is closed
   *
   * @example
   * ```typescript
   * // Seek to 30 seconds
   * const ret = await input.seek(30);
   * FFmpegError.throwIfError(ret, 'seek failed');
   * ```
   *
   * @example
   * ```typescript
   * import { AVSEEK_FLAG_BACKWARD } from 'node-av/constants';
   *
   * // Seek to keyframe before 60 seconds
   * await input.seek(60, -1, AVSEEK_FLAG_BACKWARD);
   * ```
   *
   * @see {@link AVSeekFlag} For seek flags
   */
  async seek(timestamp: number, streamIndex = -1, flags: AVSeekFlag = AVFLAG_NONE): Promise<number> {
    if (this.isClosed) {
      throw new Error('Cannot seek on closed input');
    }

    // Convert seconds to AV_TIME_BASE
    const ts = BigInt(Math.floor(timestamp * 1000000));
    return this.formatContext.seekFrame(streamIndex, ts, flags);
  }

  /**
   * Seek to timestamp in media synchronously.
   * Synchronous version of seek.
   *
   * Seeks to the specified position in seconds.
   * Can seek in specific stream or globally.
   *
   * Direct mapping to av_seek_frame().
   *
   * @param timestamp - Target position in seconds
   *
   * @param streamIndex - Stream index or -1 for global (default: -1)
   *
   * @param flags - Seek flags (default: AVFLAG_NONE)
   *
   * @returns 0 on success, negative on error
   *
   * @throws {Error} If input is closed
   *
   * @example
   * ```typescript
   * // Seek to 30 seconds
   * const ret = input.seekSync(30);
   * FFmpegError.throwIfError(ret, 'seek failed');
   * ```
   *
   * @example
   * ```typescript
   * import { AVSEEK_FLAG_BACKWARD } from 'node-av/constants';
   *
   * // Seek to keyframe before 60 seconds
   * input.seekSync(60, -1, AVSEEK_FLAG_BACKWARD);
   * ```
   *
   * @see {@link seek} For async version
   */
  seekSync(timestamp: number, streamIndex = -1, flags: AVSeekFlag = AVFLAG_NONE): number {
    if (this.isClosed) {
      throw new Error('Cannot seek on closed input');
    }

    // Convert seconds to AV_TIME_BASE
    const ts = BigInt(Math.floor(timestamp * 1000000));
    return this.formatContext.seekFrameSync(streamIndex, ts, flags);
  }

  /**
   * Start the internal demux thread for handling multiple parallel packet generators.
   * This thread reads packets from the format context and distributes them to queues.
   *
   * @internal
   */
  private startDemuxThread(): void {
    if (this.demuxThreadActive || this.demuxThread) {
      return; // Already running
    }

    this.demuxThreadActive = true;
    this.demuxThread = (async () => {
      using packet = new Packet();
      packet.alloc();

      while (this.demuxThreadActive && !this.isClosed) {
        // Check if all queues are full - if so, wait a bit
        let allQueuesFull = true;
        for (const queue of this.packetQueues.values()) {
          if (queue.length < MAX_INPUT_QUEUE_SIZE) {
            allQueuesFull = false;
            break;
          }
        }

        if (allQueuesFull) {
          await new Promise(setImmediate);
          continue;
        }

        // Read next packet
        const ret = await this.formatContext.readFrame(packet);
        if (ret < 0) {
          // End of stream - notify all waiting consumers
          this.demuxEof = true;
          for (const resolve of this.queueResolvers.values()) {
            resolve();
          }
          this.queueResolvers.clear();
          break;
        }

        // Get stream for timestamp processing
        const stream = this._streams[packet.streamIndex];
        if (stream) {
          packet.timeBase = stream.timeBase;
          this.ptsWrapAroundCorrection(packet, stream);
          this.timestampDiscontinuityProcess(packet, stream);
          this.dtsPredict(packet, stream);
        }

        // Find which queues need this packet
        const allQueue = this.packetQueues.get('all');
        const streamQueue = this.packetQueues.get(packet.streamIndex);

        const targetQueues: { queue: Packet[]; event: string }[] = [];

        if (allQueue && allQueue.length < MAX_INPUT_QUEUE_SIZE) {
          targetQueues.push({ queue: allQueue, event: 'packet-all' });
        }

        // Only add stream queue if it's different from 'all' queue
        if (streamQueue && streamQueue !== allQueue && streamQueue.length < MAX_INPUT_QUEUE_SIZE) {
          targetQueues.push({ queue: streamQueue, event: `packet-${packet.streamIndex}` });
        }

        if (targetQueues.length === 0) {
          // No queue needs this packet, skip it
          packet.unref();
          continue;
        }

        // Clone once, then share reference for additional queues
        const firstClone = packet.clone();
        if (!firstClone) {
          throw new Error('Failed to clone packet in demux thread (out of memory)');
        }

        // Add to first queue and resolve waiting promise
        const firstKey = targetQueues[0].event.replace('packet-', '') === 'all' ? 'all' : packet.streamIndex;
        targetQueues[0].queue.push(firstClone);
        const firstResolver = this.queueResolvers.get(firstKey);
        if (firstResolver) {
          firstResolver();
          this.queueResolvers.delete(firstKey);
        }

        // Additional queues get clones (shares data buffer via reference counting)
        for (let i = 1; i < targetQueues.length; i++) {
          const additionalClone = firstClone.clone();
          if (!additionalClone) {
            throw new Error('Failed to clone packet for additional queue (out of memory)');
          }
          const queueKey = targetQueues[i].event.replace('packet-', '') === 'all' ? 'all' : packet.streamIndex;
          targetQueues[i].queue.push(additionalClone);
          const resolver = this.queueResolvers.get(queueKey);
          if (resolver) {
            resolver();
            this.queueResolvers.delete(queueKey);
          }
        }

        packet.unref();
      }

      this.demuxThreadActive = false;
    })();
  }

  /**
   * Stop the internal demux thread.
   *
   * @internal
   */
  private async stopDemuxThread(): Promise<void> {
    if (!this.demuxThreadActive) {
      return;
    }

    this.demuxThreadActive = false;
    if (this.demuxThread) {
      await this.demuxThread;
      this.demuxThread = null;
    }

    // Clear all queues and resolvers
    for (const queue of this.packetQueues.values()) {
      for (const packet of queue) {
        packet.free();
      }
      queue.length = 0;
    }
    this.packetQueues.clear();
    this.queueResolvers.clear();
    this.demuxEof = false;
  }

  /**
   * Get or create stream state for timestamp processing.
   *
   * @param streamIndex - Stream index
   *
   * @returns Stream state
   *
   * @internal
   */
  private getStreamState(streamIndex: number): StreamState {
    let state = this.streamStates.get(streamIndex);
    if (!state) {
      state = {
        wrapCorrectionDone: false,
        sawFirstTs: false,
        firstDts: AV_NOPTS_VALUE,
        nextDts: AV_NOPTS_VALUE,
        dts: AV_NOPTS_VALUE,
      };
      this.streamStates.set(streamIndex, state);
    }
    return state;
  }

  /**
   * PTS Wrap-Around Correction.
   *
   * Based on FFmpeg's ts_fixup().
   *
   * Corrects timestamp wrap-around for streams with limited timestamp bits.
   * DVB streams typically use 31-bit timestamps that wrap around.
   * Without correction, timestamps become negative causing playback errors.
   *
   * Handles:
   * - Detects wrap-around based on pts_wrap_bits from stream
   * - Applies correction once per stream
   * - Corrects both PTS and DTS
   *
   * @param packet - Packet to correct
   *
   * @param stream - Stream metadata
   *
   * @internal
   */
  private ptsWrapAroundCorrection(packet: Packet, stream: Stream): void {
    const state = this.getStreamState(packet.streamIndex);

    // Already corrected or no wrap bits configured
    if (state.wrapCorrectionDone || stream.ptsWrapBits >= 64) {
      return;
    }

    const startTime = this.formatContext.startTime;
    if (startTime === AV_NOPTS_VALUE) {
      return;
    }

    const ptsWrapBits = stream.ptsWrapBits;

    // Rescale start_time to packet's timebase
    // Note: packet.timeBase was set to stream.timeBase in packets() generator
    const stime = avRescaleQ(startTime, AV_TIME_BASE_Q, packet.timeBase);
    const stime2 = stime + (1n << BigInt(ptsWrapBits));

    state.wrapCorrectionDone = true;

    const wrapThreshold = stime + (1n << BigInt(ptsWrapBits - 1));

    // Check DTS for wrap-around
    if (stime2 > stime && packet.dts !== AV_NOPTS_VALUE && packet.dts > wrapThreshold) {
      packet.dts -= 1n << BigInt(ptsWrapBits);
      state.wrapCorrectionDone = false; // May wrap again
    }

    // Check PTS for wrap-around
    if (stime2 > stime && packet.pts !== AV_NOPTS_VALUE && packet.pts > wrapThreshold) {
      packet.pts -= 1n << BigInt(ptsWrapBits);
      state.wrapCorrectionDone = false; // May wrap again
    }
  }

  /**
   * DTS Prediction and Update.
   *
   * Based on FFmpeg's ist_dts_update().
   *
   * Predicts next expected DTS for frame ordering validation and discontinuity detection.
   * Uses codec-specific logic:
   * - Audio: Based on sample_rate and frame_size
   * - Video: Based on framerate or duration
   *
   * Handles:
   * - First timestamp initialization
   * - Codec-specific duration calculation
   * - DTS sequence tracking
   *
   * @param packet - Packet to process
   *
   * @param stream - Stream metadata
   *
   * @internal
   */
  private dtsPredict(packet: Packet, stream: Stream): void {
    const state = this.getStreamState(packet.streamIndex);
    const par = stream.codecpar;

    // First timestamp seen
    if (!state.sawFirstTs) {
      // For video with avg_frame_rate, account for video_delay
      const avgFrameRate = stream.avgFrameRate;
      if (avgFrameRate && avgFrameRate.num > 0) {
        const frameRateD = Number(avgFrameRate.num) / Number(avgFrameRate.den);
        state.firstDts = state.dts = BigInt(Math.floor((-par.videoDelay * Number(AV_TIME_BASE)) / frameRateD));
      } else {
        state.firstDts = state.dts = 0n;
      }

      if (packet.pts !== AV_NOPTS_VALUE) {
        const ptsDts = avRescaleQ(packet.pts, packet.timeBase, AV_TIME_BASE_Q);
        state.firstDts += ptsDts;
        state.dts += ptsDts;
      }
      state.sawFirstTs = true;
    }

    // Initialize next_dts if not set
    if (state.nextDts === AV_NOPTS_VALUE) {
      state.nextDts = state.dts;
    }

    // Update from packet DTS if available
    if (packet.dts !== AV_NOPTS_VALUE) {
      state.nextDts = state.dts = avRescaleQ(packet.dts, packet.timeBase, AV_TIME_BASE_Q);
    }

    state.dts = state.nextDts;

    // Predict next DTS based on codec type
    switch (par.codecType) {
      case AVMEDIA_TYPE_AUDIO:
        // Audio: duration from sample_rate or packet duration
        if (par.sampleRate > 0 && par.frameSize > 0) {
          state.nextDts += (BigInt(AV_TIME_BASE) * BigInt(par.frameSize)) / BigInt(par.sampleRate);
        } else {
          state.nextDts += avRescaleQ(packet.duration, packet.timeBase, AV_TIME_BASE_Q);
        }
        break;

      case AVMEDIA_TYPE_VIDEO: {
        // Video: various methods depending on available metadata
        // Note: FFmpeg has ist->framerate (forced with -r), but we don't support that option
        if (packet.duration > 0n) {
          // Use packet duration
          state.nextDts += avRescaleQ(packet.duration, packet.timeBase, AV_TIME_BASE_Q);
        } else if (par.frameRate && par.frameRate.num > 0) {
          // Use codec framerate with field handling
          const fieldRate = avMulQ(par.frameRate, { num: 2, den: 1 });
          let fields = 2; // Default: 2 fields (progressive or standard interlaced)

          // Check if parser is available for accurate field count
          const parser = stream.parser;
          if (parser) {
            // Get repeat_pict from parser for accurate field count
            fields = 1 + parser.repeatPict;
          }

          const invFieldRate = avInvQ(fieldRate);
          state.nextDts += avRescaleQ(BigInt(fields), invFieldRate, AV_TIME_BASE_Q);
        }
        break;
      }
    }
  }

  /**
   * Timestamp Discontinuity Detection.
   *
   * Based on FFmpeg's ts_discontinuity_detect().
   *
   * Detects and corrects timestamp discontinuities in streams.
   * Handles two cases:
   * - Discontinuous formats (MPEG-TS): Apply offset correction
   * - Continuous formats (MP4): Mark timestamps as invalid
   *
   * Handles:
   * - Format-specific discontinuity handling (AVFMT_TS_DISCONT flag)
   * - PTS wrap-around detection for streams with limited timestamp bits
   * - Intra-stream discontinuity detection
   * - Inter-stream discontinuity detection
   * - Offset accumulation and application
   * - copyTs mode with selective correction
   *
   * @param packet - Packet to check for discontinuities
   *
   * @param stream - Stream metadata
   *
   * @internal
   */
  private timestampDiscontinuityDetect(packet: Packet, stream: Stream): void {
    const state = this.getStreamState(packet.streamIndex);
    const inputFormat = this.formatContext.iformat;

    // Check if format declares timestamp discontinuities
    const fmtIsDiscont = !!(inputFormat && inputFormat.flags & AVFMT_TS_DISCONT);

    // Disable correction when copyTs is enabled
    let disableDiscontinuityCorrection = this.options.copyTs;

    // Rescale packet DTS to AV_TIME_BASE for comparison
    const pktDts = avRescaleQRnd(packet.dts, packet.timeBase, AV_TIME_BASE_Q, (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX) as any);

    // PTS wrap-around detection
    // Only applies when copyTs is enabled and stream has limited timestamp bits
    if (this.options.copyTs && state.nextDts !== AV_NOPTS_VALUE && fmtIsDiscont && stream.ptsWrapBits < 60) {
      // Calculate wrapped DTS by adding 2^pts_wrap_bits to packet DTS
      const wrapDts = avRescaleQRnd(packet.dts + (1n << BigInt(stream.ptsWrapBits)), packet.timeBase, AV_TIME_BASE_Q, (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX) as any);

      // If wrapped DTS is closer to predicted nextDts, enable correction
      const wrapDelta = wrapDts > state.nextDts ? wrapDts - state.nextDts : state.nextDts - wrapDts;
      const normalDelta = pktDts > state.nextDts ? pktDts - state.nextDts : state.nextDts - pktDts;

      if (wrapDelta < normalDelta / 10n) {
        disableDiscontinuityCorrection = false;
      }
    }

    // Intra-stream discontinuity detection
    if (state.nextDts !== AV_NOPTS_VALUE && !disableDiscontinuityCorrection) {
      const delta = pktDts - state.nextDts;

      if (fmtIsDiscont) {
        // Discontinuous format (e.g., MPEG-TS) - apply offset correction
        const threshold = BigInt(this.options.dtsDeltaThreshold) * BigInt(AV_TIME_BASE);

        if (delta > threshold || delta < -threshold || pktDts + BigInt(AV_TIME_BASE) / 10n < state.dts) {
          this.tsOffsetDiscont -= delta;

          // Apply correction to packet
          const deltaInPktTb = avRescaleQ(delta, AV_TIME_BASE_Q, packet.timeBase);
          packet.dts -= deltaInPktTb;
          if (packet.pts !== AV_NOPTS_VALUE) {
            packet.pts -= deltaInPktTb;
          }
        }
      } else {
        // Continuous format (e.g., MP4) - mark invalid timestamps
        const threshold = BigInt(this.options.dtsErrorThreshold) * BigInt(AV_TIME_BASE);

        // Check DTS
        if (delta > threshold || delta < -threshold) {
          packet.dts = AV_NOPTS_VALUE;
        }

        // Check PTS
        if (packet.pts !== AV_NOPTS_VALUE) {
          const pktPts = avRescaleQ(packet.pts, packet.timeBase, AV_TIME_BASE_Q);
          const ptsDelta = pktPts - state.nextDts;
          if (ptsDelta > threshold || ptsDelta < -threshold) {
            packet.pts = AV_NOPTS_VALUE;
          }
        }
      }
    } else if (state.nextDts === AV_NOPTS_VALUE && !this.options.copyTs && fmtIsDiscont && this.lastTs !== AV_NOPTS_VALUE) {
      // Inter-stream discontinuity detection
      const delta = pktDts - this.lastTs;
      const threshold = BigInt(this.options.dtsDeltaThreshold) * BigInt(AV_TIME_BASE);

      if (delta > threshold || delta < -threshold) {
        this.tsOffsetDiscont -= delta;

        // Apply correction to packet
        const deltaInPktTb = avRescaleQ(delta, AV_TIME_BASE_Q, packet.timeBase);
        packet.dts -= deltaInPktTb;
        if (packet.pts !== AV_NOPTS_VALUE) {
          packet.pts -= deltaInPktTb;
        }
      }
    }

    // Update last timestamp
    this.lastTs = avRescaleQ(packet.dts, packet.timeBase, AV_TIME_BASE_Q);
  }

  /**
   * Timestamp Discontinuity Processing - main entry point.
   *
   * Based on FFmpeg's ts_discontinuity_process().
   *
   * Applies accumulated discontinuity offset and detects new discontinuities.
   * Must be called for every packet before other timestamp processing.
   *
   * Handles:
   * - Applying previously-detected offset to all streams
   * - Detecting new discontinuities for audio/video streams
   *
   * @param packet - Packet to process
   *
   * @param stream - Stream metadata
   *
   * @internal
   */
  private timestampDiscontinuityProcess(packet: Packet, stream: Stream): void {
    // Apply previously-detected discontinuity offset
    // This applies to ALL streams, not just audio/video
    const offset = avRescaleQ(this.tsOffsetDiscont, AV_TIME_BASE_Q, packet.timeBase);
    if (packet.dts !== AV_NOPTS_VALUE) {
      packet.dts += offset;
    }
    if (packet.pts !== AV_NOPTS_VALUE) {
      packet.pts += offset;
    }

    // Detect new timestamp discontinuities for audio/video
    const par = stream.codecpar;
    if ((par.codecType === AVMEDIA_TYPE_VIDEO || par.codecType === AVMEDIA_TYPE_AUDIO) && packet.dts !== AV_NOPTS_VALUE) {
      this.timestampDiscontinuityDetect(packet, stream);
    }
  }

  /**
   * Close demuxer and free resources.
   *
   * Releases format context and I/O context.
   * Safe to call multiple times.
   * Automatically called by Symbol.asyncDispose.
   *
   * Direct mapping to avformat_close_input().
   *
   * @example
   * ```typescript
   * const input = await Demuxer.open('video.mp4');
   * try {
   *   // Use input
   * } finally {
   *   await input.close();
   * }
   * ```
   *
   * @see {@link Symbol.asyncDispose} For automatic cleanup
   */
  async close(): Promise<void> {
    if (this.isClosed) {
      return;
    }

    this.isClosed = true;

    // Clear pb reference FIRST to prevent use-after-free
    if (this.ioContext) {
      this.formatContext.pb = null;
    }

    // IMPORTANT: Close FormatContext BEFORE stopping demux thread
    // This interrupts any blocking read() calls in the demux loop
    await this.formatContext.closeInput();

    // Safely stop the demux thread
    await this.stopDemuxThread();

    // NOW we can safely free the IOContext
    if (this.ioContext) {
      this.ioContext.freeContext();
      this.ioContext = undefined;
    }
  }

  /**
   * Close demuxer and free resources synchronously.
   * Synchronous version of close.
   *
   * Releases format context and I/O context.
   * Safe to call multiple times.
   * Automatically called by Symbol.dispose.
   *
   * Direct mapping to avformat_close_input().
   *
   * @example
   * ```typescript
   * const input = Demuxer.openSync('video.mp4');
   * try {
   *   // Use input
   * } finally {
   *   input.closeSync();
   * }
   * ```
   *
   * @see {@link close} For async version
   */
  closeSync(): void {
    if (this.isClosed) {
      return;
    }

    this.isClosed = true;

    // IMPORTANT: Clear pb reference FIRST to prevent use-after-free
    if (this.ioContext) {
      this.formatContext.pb = null;
    }

    // Close FormatContext
    this.formatContext.closeInputSync();

    this.demuxThreadActive = false;

    for (const queue of this.packetQueues.values()) {
      for (const packet of queue) {
        packet.free();
      }
      queue.length = 0;
    }
    this.packetQueues.clear();
    this.queueResolvers.clear();
    this.demuxEof = false;

    // NOW we can safely free the IOContext
    if (this.ioContext) {
      this.ioContext.freeContext();
      this.ioContext = undefined;
    }
  }

  /**
   * Get underlying format context.
   *
   * Returns the internal format context for advanced operations.
   *
   * @returns Format context
   *
   * @internal
   */
  getFormatContext(): FormatContext {
    return this.formatContext;
  }

  /**
   * Dispose of demuxer.
   *
   * Implements AsyncDisposable interface for automatic cleanup.
   * Equivalent to calling close().
   *
   * @example
   * ```typescript
   * {
   *   await using input = await Demuxer.open('video.mp4');
   *   // Process media...
   * } // Automatically closed
   * ```
   *
   * @see {@link close} For manual cleanup
   */
  async [Symbol.asyncDispose](): Promise<void> {
    await this.close();
  }

  /**
   * Dispose of demuxer synchronously.
   *
   * Implements Disposable interface for automatic cleanup.
   * Equivalent to calling closeSync().
   *
   * @example
   * ```typescript
   * {
   *   using input = Demuxer.openSync('video.mp4');
   *   // Process media...
   * } // Automatically closed
   * ```
   *
   * @see {@link closeSync} For manual cleanup
   */
  [Symbol.dispose](): void {
    this.closeSync();
  }
}
